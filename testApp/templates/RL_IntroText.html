{% extends 'base.html' %}
{% block body %}
{% load static %}
<div class="row">
    <div class="col">
        <div class="card">
            <div class="card-content">
                <span class="card-title center-align deep-orange-text text-darken-2">Reinforcement Learning ржП рж╣рж╛рждрзЗржЦрзЬрж┐</span>
                <p class="center-left">
                  ржХрж┐ржЫрзБ рж╣рж╛ржмрж┐ржЬрж╛ржмрж┐ ржХржерж╛ ржжрж┐рзЯрзЗржЗ ржЖржЬржХрзЗрж░ ржкрж░рзНржмржЯрж╛ рж╢рзБрж░рзБ ржХрж░рж┐ред 
                  ржоржирзЗ ржХрж░рзБржи, ржЖржорж┐ ржЖрж░ ржЖржкржирж┐ ржжрж╛ржмрж╛ ржЦрзЗрж▓ржЫрж┐ред 
                  ржЖржорж┐ рж╕рж╛ржжрж╛ ржЧрзБржЯрж┐ ржирж┐рзЯрзЗржЫрж┐ ржЖрж░ ржЖржкржирж┐ ржХрж╛рж▓рзЛ ржЧрзБржЯрж┐ред ржЖржорж┐ ржкрзНрж░ржержорзЗ ржЪрж╛рж▓ ржжрж┐рж▓рж╛ржоред 
                  ржПржЦржи ржЖржкржирж╛рж░ ржЪрж╛рж▓ ржжрзЗржУрзЯрж╛рж░ ржкрж╛рж▓рж╛ред ржЖржкржирж┐ ржХрж┐ randomly ржПржХржЯрж╛ ржХрж┐ржЫрзБ ржЪрж╛рж▓ ржжрж┐рзЯрзЗ ржжрж┐ржмрзЗржи ржирж╛ржХрж┐ ржЖржорж┐ ржкрзНрж░ржержорзЗ ржЪрж╛рж▓ржЯрж╛ ржХрзЗржи ржжрж┐рзЯрзЗржЫрж┐ рж╕рзЗржЯрж╛рж░ ржкрж┐ржЫржирзЗ ржорзЛржЯрж┐ржн ржЦрзБржБржЬрзЗ ржирж┐ржЬрзЗрж░ ржЬржирзНржп strategy рждрзИрж░рж┐ ржХрж░ржмрзЗржи? 
                  рж╣рзЯржд ржкрзНрж░ржержо ржЪрж╛рж▓рзЗрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ ржорзЛржЯрж┐ржн ржХрж░рждрзЗ ржкрж╛рж░ржмрзЗржи ржирж╛ ржХрж┐ржирзНрждрзБ ржЖржорж╛рж░ 3-4 ржЯрж╛ ржЪрж╛рж▓ ржжрзЗржЦрж╛рж░ ржкрж░ ржирж┐рж╢рзНржЪрзЯ ржмрзБржЭрждрзЗ ржкрж╛рж░ржмрзЗржи ржЖржорж┐ ржЖрж╕рж▓рзЗ ржХрж┐ ржХрж░рждрзЗ ржпрж╛ржЪрзНржЫрж┐ред 
                  рждрж╛рж░ржкрж░ рж╕рзЗржЗ ржЕржирзБржпрж╛рзЯрзА ржЖржкржирж┐ ржЖржкржирж╛рж░ strategy build ржХрж░ржмрзЗржиред рждрж╛ржЗ ржирж╛?<br><br>
                  ржПржЦржи ржХржерж╛ рж╣рж▓, ржЖржкржирж┐ ржХрж┐ржнрж╛ржмрзЗ ржЖржорж╛рж░ ржжрзЗржУрзЯрж╛ ржЪрж╛рж▓рзЗрж░ ржкрж┐ржЫржирзЗ ржЖржорж╛рж░ ржорзЛржЯрж┐ржн ржЦрзБржБржЬрзЗ ржмрзЗрж░ ржХрж░ржмрзЗржи? 
                  ржЖржкржирж┐ ржЖржкржирж╛рж░ ржмрзЛрж░рзНржбрзЗрж░ рж╕рж╛ржоржирзЗ ржмрж╕рзЗ ржЖржЫрзЗржиред ржмрзЛрж░рзНржбрзЗрж░ ржЧрзБржЯрж┐рж░ ржмрж░рзНрждржорж╛ржи position рж╣рж▓ ржПржХржЯрж╛ stateред 
                  ржмрж░рзНрждржорж╛ржи state ржП ржХрзЛржи ржПржХржЯрж╛ ржЪрж╛рж▓ ржжрзЗржУрзЯрж╛рж░ ржкрж░рзЗ ржЖржорж┐ ржХрж┐ ржЪрж╛рж▓ ржжрж┐рждрзЗ ржкрж╛рж░рж┐, рждрж╛рж░ржкрж░ ржЖржкржирж┐ ржХрж┐ ржЪрж╛рж▓ ржжрж┐рждрзЗ ржкрж╛рж░рзЗржи ржПрж░ржХржо ржЕржирзЗржХржЧрзБрж▓рзЛ future state ржоржирзЗ ржоржирзЗ рж╕рж┐ржорзБрж▓рзЗржЯ ржХрж░рзЗ ржХрж░рзЗ ржЖржорж╛рж░ ржорзЛржЯрж┐ржн ржмрзЗрж░ ржХрж░ржмрзЗржиред<br>
                  ржПржмрж╛рж░ ржХрж╛ржЬрзЗрж░ ржХржерж╛рзЯ ржЖрж╕рж┐ред Reinforcement Learning ржЖрж╕рж▓рзЗ ржПржХ ржзрж░ржирзЗрж░ DP ржЯрж╛ржЗржк algorithm ржпрзЗржЦрж╛ржирзЗ ржоржбрзЗрж▓ ржЯрзНрж░рзЗржЗржи рж╣рзЯ reward ржЖрж░ punishment ржПрж░ ржжрзНржмрж╛рж░рж╛ред Supervised Learning, ржЯрзНрж░рзЗржирж┐ржВ ржбрж╛ржЯрж╛рж░ рж╕рж╛ржерзЗ рж▓рзЗржнрзЗрж▓ржХрзЗ ржлрж┐ржЯ ржХрж░рж╛рж░ ржЬржирзНржп ржоржбрзЗрж▓ржХрзЗ ржЯрзНрж░рзЗржЗржи ржХрж░рзЗред 
                  ржЕржкрж░ржжрж┐ржХрзЗ, Reinforcement Learning ржП ржоржбрзЗрж▓/agent-ржХрзЗ ржЯрзНрж░рзЗржЗржи ржХрж░рж╛ рж╣рзЯ ржорзНржпрж╛ржХрзНрж╕рж┐ржорж╛ржо reward ржкрж╛ржУрзЯрж╛рж░ ржЬржирзНржпред<br><br>
                  рж╕рж╣ржЬ ржнрж╛рж╖рж╛рзЯ ржмрж▓рждрзЗ ржЧрзЗрж▓рзЗ, Reinforcement Learning ржП ржХржорзНржкрж┐ржЙржЯрж╛рж░ржХрзЗ ржПржоржиржнрж╛ржмрзЗ ржЯрзНрж░рзЗржЗржи ржХрж░рж╛ рж╣рзЯ ржпрзЗржи рж╕рзЗ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржПржХржЯрж┐ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж▓ржХрзНрж╖рзНржпрзЗрж░ ржжрж┐ржХрзЗ efficient way рждрзЗ ржкрзМржЫрж╛рждрзЗ ржкрж╛рж░рзЗред<br>
                  ржПржнрж╛ржмрзЗ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржПржХржЯрж┐ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ рж▓ржХрзНрж╖рзНржпрзЗрж░ ржжрж┐ржХрзЗ ржкрзМржЫрж╛ржирзЛрж░ ржЬржирзНржп Markov Decision Process(MDP) ржмрзНржпржмрж╣рж╛рж░ ржХрж░рж╛ рж╣рзЯред<br><br>
                  ржЖржкржирж┐ ржирж┐рж╢рзНржЪрзЯржЗ ржЪрж┐ржирзНрждрж╛ ржХрж░ржЫрзЗржи, ржХрзЗ ржПржЗ agent? ржХрж┐рж╕рзЗрж░ reward, ржХрж┐рж╕рзЗрж░ punishment? ржПржЗ Markov Decision Process-ржЗ ржЖржмрж╛рж░ ржХрж┐?<br><br>
                  Agent, punishment, reward рж╣ржЪрзНржЫрзЗ ржПржЗ Markov Decision Process- ржПрж░ componentред 
                  ржЖржорж░рж╛ ржкрзНрж░ржержорзЗ ржПржЗ component ржЧрзБрж▓рзЛржХрзЗ ржЪрж┐ржиржм рждрж╛рж░ржкрж░ Markov Decision Process ржирж┐рзЯрзЗ ржЖрж▓рзЛржЪржирж╛ ржХрж░ржмред<br>
                  <span class="deep-orange-text text-darken-2">Agent:</span> рж╢рзБрж░рзБрждрзЗ ржжрж╛ржмрж╛ ржЦрзЗрж▓рж╛рж░ ржпрзЗ ржЙржжрж╛рж╣рж░ржгржЯрж╛ ржжрж┐рж▓рж╛ржо рж╕рзЗржЦрж╛ржирзЗ ржЖржкржирж┐ рж╣ржЪрзНржЫрзЗржи Agentред 
                  Reinforcement Learning- ржПрж░ ржХрзНрж╖рзЗрждрзНрж░рзЗ agent рж╣ржЪрзНржЫрзЗ ржХржорзНржкрж┐ржЙржЯрж╛рж░ред<br>
                  <span class="deep-orange-text text-darken-2">Reward:</span> Reward рж╣ржЪрзНржЫрзЗ destination ржП ржкрзМржЫрж╛ржирзЛрж░ measurementред 
                  ржоржирзЗ ржХрж░рзБржи, ржЙржкрж░рзЗрж░ ржЙржжрж╛рж╣рж░ржгрзЗ ржжрж╛ржмрж╛ ржЦрзЗрж▓рж╛рзЯ ржпржжрж┐ ржЖржкржирж┐ ржЬрж┐рждрзЗ ржпрж╛ржи рждрж╛рж╣рж▓рзЗ reward ржкрж╛ржмрзЗржи +рззрзжред 
                  ржПржЦржи ржХрзЛржи ржПржХржЯрж╛ ржЪрж╛рж▓ ржжрж┐рж▓рзЗ ржпржжрж┐ ржЖржкржирж┐ ржкрж╛ржи +рзп рждрж╛рж░ржорж╛ржирзЗ ржПржЯрж┐ ржПржХржЯрж┐ ржнрж╛рж▓рзЛ ржЪрж╛рж▓ ржЖрж░ ржПрждрзЗ ржЖржкржирж╛рж░ ржЬрзЗрждрж╛рж░ рж╕ржорзНржнрж╛ржмржирж╛ ржЕржирзЗржХ ржмрзЗрж╢рзАред
                  ржЖржмрж╛рж░ ржХрзЛржи ржЪрж╛рж▓ ржжрж┐рж▓рзЗ reward ржкрж╛ржмрзЗржи +рзл рждрж╛рж░ржорж╛ржирзЗ ржПржЗ ржЪрж╛рж▓ржЯрж╛ ржЖржЧрзЗрж░ ржЪрж╛рж▓рзЗрж░ ржоржд (+рзп ржкрж╛ржУрзЯрж╛ ржЪрж╛рж▓рзЗрж░ ржоржд) ржПржд ржнрж╛рж▓рзЛ ржирж╛ред<br>
                  <span class="deep-orange-text text-darken-2">Punishment:</span> ржмрзБржЭрждрзЗржЗ ржкрж╛рж░ржЫрзЗржи ржПржЯрж╛ Reward ржПрж░ ржарж┐ржХ ржЙрж▓рзНржЯрзЛред
                  ржЧрзЗржорзЗрж░ рж╢рзБрж░рзБ ржпрзЗржоржи Reward value ржарж┐ржХ ржХрж░рж╛ рж╣рзЯрзЗ ржерзЗржХрзЗ рждрзЗржоржи Punishment value-ржУ ржарж┐ржХ ржХрж░рж╛ рж╣рзЯрзЗ ржерж╛ржХрзЗред<br>
                  <span class="deep-orange-text text-darken-2">State:</span> ржХрзЛржи t ржЯрж╛ржЗржорзЗ ржжрж╛ржмрж╛рж░ ржмрзЛрж░рзНржбрзЗ рж╕ржм ржЧрзБржЯрж┐рж░ ржЕржмрж╕рзНржерж╛ржи рж╣рж▓ t ржЯрж╛ржЗржорзЗрж░ state.<br>
                  <span class="deep-orange-text text-darken-2">Action:</span> ржЖржкржирж╛рж░ ржжрзЗржУрзЯрж╛ ржкрзНрж░рждрж┐ржЯрж┐ ржЪрж╛рж▓ рж╣ржЪрзНржЫрзЗ action.<br>
                  <span class="deep-orange-text text-darken-2">Environment:</span> Agent ржпрзЗржЦрж╛ржирзЗ action ржирзЗрзЯ рж╕рзЗржЯрж╛ рж╣ржЪрзНржЫрзЗ environment. ржПржЦрж╛ржирзЗ Environment рж╣рж▓ ржжрж╛ржмрж╛рж░ ржмрзЛрж░рзНржбред<br>
                  <img style="margin-left: 340px;" src="{% static "RL_intro.png" %}" width="550" height="300"><br>
                  Markov Decision Process ржХрж┐ рж╕рзЗржЯрж╛ рж╕рж░рж╛рж╕рж░рж┐ ржмрж▓рзЗ ржзрж╛ржкрзЗ ржзрж╛ржкрзЗ ржЬрж╛ржиржмред ржкрзНрж░ржержорзЗржЗ ржЖржорж░рж╛ ржЬрж╛ржиржм <span class="deep-orange-text text-darken-2">Markov Property</span> ржХрж┐?
                  <blockquote>The future is independent of the past given the present.</blockquote>
                  T ржЯрж╛ржЗржорзЗ ржХрзЛржи рж╕рзНржЯрзЗржЯ ржпржжрж┐ ржЕрждрзАрждрзЗрж░ рж╕ржмржЧрзБрж▓рзЛ рж╕рзНржЯрзЗржЯрзЗрж░ ржкрзНрж░рзЯрзЛржЬржирзАрзЯ рж╕ржм information рж░рж╛ржЦрзЗ рждрж╛рж╣рж▓рзЗ ржнржмрж┐рж╖рзНржпрждрзЗрж░ рж╕рзНржЯрзЗржЯржЧрзБрж▓рзЛ ржЕрждрзАрждрзЗрж░ ржХрзЛржи рж╕рзНржЯрзЗржЯрзЗрж░ ржЙржкрж░ ржирж┐рж░рзНржнрж░ ржХрж░рзЗ ржирж╛ред 
                  ржПржЯрж╛ржЗ Markov property. рж╕рзБрждрж░рж╛ржВ
                  <img style="margin-left: 420px;" src="{% static "e1.jpg" %}"><br><br>
                  ржПржмрж╛рж░ ржЖржорж░рж╛ ржЬрж╛ржиржм <span class="deep-orange-text text-darken-2">Markov Process</span> ржХрж┐? Markov Process рж╣ржЪрзНржЫрзЗ ржХрж┐ржЫрзБ memory-less state ржПрж░ sequence ржкрзНрж░рж╕рзЗрж╕ ржпрж╛рж░рж╛ markov property ржХрзНржпрж╛рж░рж┐ ржХрж░рзЗред 
                  (S, P) ржПржЗ tuple ржХрзЗ markov property ржмрж▓рзЗред 
                  ржПржЦрж╛ржирзЗ S рж╣ржЪрзНржЫрзЗ State Space ржЖрж░ P рж╣ржЪрзНржЫрзЗ Transition Probability function.<br><br>
                  ржжрзЗржЦрзБржи, Markov Process ржП ржмрж▓рж╛ рж╣ржЪрзНржЫрзЗ ржкрж░ржкрж░ ржЕржирзЗржХржЧрзБрж▓рзЛ рж╕рзНржЯрзЗржЯрзЗрж░ sequence. 
                  ржХрж┐ржирзНрждрзБ ржПржХржЯрж╛ рж╕рзНржЯрзЗржЯ ржерзЗржХрзЗ ржЕржирзЗржХржЧрзБрж▓рзЛ рж╕рзНржЯрзЗржЯрзЗ ржпрж╛ржУрзЯрж╛ ржпрзЗрждрзЗ ржкрж╛рж░рзЗред
                  рждрж╛ржЗ ржХрзЛржи рж╕рзНржЯрзЗржЯ ржерзЗржХрзЗ ржХрзЛржи рж╕рзНржЯрзЗржЯрзЗ ржпрж╛ржУрзЯрж╛ ржмрзЗрж╢рзА рж▓рж╛ржнржЬржиржХ рж╕рзЗржЯрж╛ calculate ржХрж░рж╛ рж╣рзЯ reward ржнрж╛рж▓рзНржпрзБ ржжрж┐рзЯрзЗред
                  <span class="deep-orange-text text-darken-2">Markov Reward Process(MRP)</span> рж╣ржЪрзНржЫрзЗ ржПржХржЯрж╛ ржкрзНрж░рж╕рзЗрж╕ ржпрзЗржЦрж╛ржирзЗ ржЖржорж░рж╛ ржХрзЛржи ржПржХржЯрж╛ sequence ржерзЗржХрзЗ ржХржд reward ржкрзЗрждрзЗ ржкрж╛рж░рж┐ рж╕рзЗржЯрж╛ calculate ржХрж░рж╛ рж╣рзЯред<br><br>
                  <img style="margin-left: 280px;" src="{% static "state_action.jpg" %}"><br>
                  ржПржЦрж╛ржирзЗ ржмрзГрждрзНрждржЧрзБрж▓рзЛ рж╕рзНржЯрзЗржЯред ржПржЦржи Start ржерзЗржХрзЗ ржХрзЛржи sequence-ржП End state ржкрзМржЫрж╛рж▓рзЗ рж╕ржмржЪрзЗрзЯрзЗ ржмрзЗрж╢рзА Reward ржХрж╛рж▓рзЗржХрзНржЯ ржХрж░рж╛ ржпрж╛ржмрзЗ рж╕рзЗржЯрж╛ржЗ MRP ржПрж░ рж╕рж╛рж╣рж╛ржпрзНржпрзЗ ржмрзЗрж░ ржХрж░рж╛ рж╣рзЯред 
                  MRP- ржХрзЗ (S, P, R, ЁЭЫ╛) ржжрж┐рзЯрзЗржУ ржмрзЛржЭрж╛ржирзЛ ржпрж╛рзЯред 
                  ╬│ рж╣рж▓ Discount factor. ╬│тИИ[0,1]. ржПржЦрж╛ржирзЗ R рж╣ржЪрзНржЫрзЗ Reward function-<br>
                  <img style="margin-left: 420px;" src="{% static "reward_function.jpg" %}"><br>
                  ржПржЦрж╛ржирзЗ ржмрзЛржЭрж╛ржирзЛ рж╣рзЯрзЗржЫрзЗ ржпрзЗ, t ржЯрж╛ржЗржорзЗ S рж╕рзНржЯрзЗржЯрзЗ ржПрж╕рзЗ R_(t+1)(ржпрзЗрж╣рзЗрждрзБ, t рж╕ржорзЯрзЗ ржПрж╕рзЗржЫрзЗржи рждрж╛ржЗ reward ржкрж╛ржУрзЯрж╛ ржпрж╛ржмрзЗ t+1 рж╕ржорзЯрзЗ) Reward ржкрж╛ржУрзЯрж╛рж░ Expectation(ржЧрж╛ржгрж┐рждрж┐ржХ ржкрзНрж░рждрзНржпрж╛рж╢рж╛)ред <br><br>
                  <span class="deep-orange-text text-darken-2">Markov Reward Process- ржПрж░ Markov рж╕рзНржЯрзЗржЯржЧрзБрж▓рзЛрж░ рж╕рж╛ржерзЗ ржЕржЗ рж╕рзНржЯрзЗржЯрзЗ ржХрж┐ ржбрж┐рж╕рж┐рж╢ржи ржирж┐ржмрзЗ ржмрж╛ Action ржирж┐ржмрзЗ рж╕рзЗржЯрж╛ ржпрзЛржЧ ржжрж┐рж▓рзЗ рж╣рзЯрзЗ ржпрж╛рзЯ Markov Decision Process.
                  ржпрж╛ржХрзЗ (S, P, A, R, ╬│) ржжрж┐рзЯрзЗ ржкрзНрж░ржХрж╛рж╢ ржХрж░рж╛ ржпрж╛рзЯред</span> ржПржЦрж╛ржирзЗ-<br>
                  <img style="margin-left: 420px;" src="{% static "ProbabilityTransferFunction.jpg" %}"><br>
                  ржПржЦрж╛ржирзЗ ржмрзЛржЭрж╛ржирзЛ рж╣рзЯрзЗржЫрзЗ ржпрзЗ, S рж╕рзНржЯрзЗржЯ ржерзЗржХрзЗ A action ржирж┐рзЯрзЗ S^/ рж╕рзНржЯрзЗржЯрзЗ ржЖрж╕рж╛рж░ Probality(рж╕ржорзНржнрж╛ржмржирж╛) ржЖрж░<br>
                  <img style="margin-left: 420px;" src="{% static "reward_function1.jpg" %}"><br>
                  ржПржЯрж╛ ржЖржЧрзЗрж░(MRP- ржПрж░) Reward function ржПрж░ ржорждржЗ рждржмрзЗ рждржЦржи ржбрж┐рж╕рж┐рж╢ржи ржмрж╛ Reward ржЯрж╛рж░рзНржоржЯрж╛ рж╕ржВржпрзБржХрзНржд ржЫрж┐рж▓ ржирж╛, ржПржЦржи ржЖржЫрзЗред<br>
                  ржПржЗ Markov Decision Process- ржЗ Reinforcement Learning- ржПрж░ ржПржХрзЗржмрж╛рж░рзЗ basic structure.<br><br>
                  Reinforcement Learning-ржП ржмрзНржпржмрж╣рзГржд ржХрж┐ржЫрзБ algorithm тАУ<br>
                  тАв Q-Learning<br>
                  тАв State-Action-Reward-State-Action(SARSA)<br>
                  тАв Deep Q-Network(DQN)<br>
                  ржЖржорж░рж╛ ржкрж░ржмрж░рзНрждрзА ржкрж░рзНржмржЧрзБрж▓рзЛрждрзЗ ржПржЗ algorithm ржЧрзБрж▓рзЛ ржирж┐рзЯрзЗ ржЖрж▓рзЛржЪржирж╛ ржХрж░ржмред ржЖржЬржХрзЗрж░ ржоржд ржПржЗржЯрзБржХрзБржЗред
                </p>
            </div>
        </div>
    </div>
</div>
                
{% endblock %}